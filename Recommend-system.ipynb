{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89b6d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d9f85bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hdoop/my_project_dir/my_project_env/lib/python3.6/site-packages/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n",
      "/home/hdoop/my_project_dir/my_project_env/lib/python3.6/site-packages/pyspark/sql/context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext, Row, SparkSession\n",
    "# Initializing Spark Session\n",
    "spark = SparkSession.builder.appName(\"Recommendation-system\").getOrCreate()\n",
    "# Getting the SparkContext\n",
    "sc = spark.sparkContext\n",
    "# Initializing the SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d1442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af07899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_dataset_path = 'data/ml-lastest/'\n",
    "small_dataset_path = 'data/ml-lastest-small/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e968a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Dataframe for the small dataset using SQLContext\n",
    "small_file = os.path.join(small_dataset_path, 'ratings.csv')\n",
    "small_raw_data = sc.textFile(small_file)\n",
    "small_raw_data_DF = sqlContext.read.csv(small_file, header=True, inferSchema=True)\n",
    "small_raw_data_header = small_raw_data.take(1)[0]\n",
    "#small_raw_data_DF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "659ba5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe for visualization in temp table 'D'\n",
    "data = sc.textFile(small_file)\n",
    "data = data.filter(lambda line: line != small_raw_data_header).map(lambda line: line.split(',')). \\\n",
    "    map(lambda x: Row(userId=int(x[0]), movieId=int(x[1]), rating=float(x[2]), timestamp=str(x[3])))\n",
    "dataDF = sqlContext.createDataFrame(data)\n",
    "dataDF.createOrReplaceTempView(\"D\")\n",
    "# Displaying the temp table \"D\"\n",
    "#print(spark.sql(\"Select * from D\").show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba368d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating RDD using only userID, movieID, rating since we don't need timestamp\n",
    "small_data = small_raw_data \\\n",
    "    .filter(lambda line: line != small_raw_data_header) \\\n",
    "    .map(lambda line: line.split(\",\")) \\\n",
    "    .map(lambda tokens: (tokens[0], tokens[1], tokens[2])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d84ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the small dataset Dataframe\n",
    "small_movies_file = os.path.join(small_dataset_path, 'movies.csv')\n",
    "small_movies_raw_data = sc.textFile(small_movies_file)\n",
    "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
    "small_movies_raw_data = sc.textFile(small_movies_file)\n",
    "data = small_movies_raw_data.filter(lambda line: line != small_movies_raw_data_header).map(\n",
    "    lambda line: line.split(',')). \\\n",
    "    map(lambda x: Row(movieId=int(x[0]), title=(x[1]).encode('utf-8')))\n",
    "dataDF = sqlContext.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "722236d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation datasets\n",
    "training_RDD, validation_RDD, test_RDD = small_data.randomSplit([6, 2, 2], seed=5)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "# ALS algorithm configuration\n",
    "seed = config.seed\n",
    "iterations = config.iterations\n",
    "regularization_parameter = config.regularization_parameter\n",
    "ranks = config.ranks\n",
    "errors = config.errors\n",
    "err = config.err\n",
    "tolerance = config.tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ed55cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS algorithm training step\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations, lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_predictions = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_predictions.map(lambda r: (r[1][0] - r[1][1]) ** 2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "284db6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was trained with rank 12\n"
     ]
    }
   ],
   "source": [
    "print('The best model was trained with rank %s' % best_rank)\n",
    "\n",
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations, lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD) \\\n",
    "    .map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_predictions = test_RDD \\\n",
    "    .map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))) \\\n",
    "    .join(predictions)\n",
    "error = math.sqrt(rates_and_predictions.map(lambda r: (r[1][0] - r[1][1]) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46a485aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.9180629959752412\n"
     ]
    }
   ],
   "source": [
    "print('For testing data the RMSE is %s' % error)\n",
    "\n",
    "large_file = os.path.join(large_dataset_path, 'movies.csv')\n",
    "large_raw_data = sc.textFile(large_file)\n",
    "large_raw_data_header = large_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b094a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the dataset\n",
    "large_data = large_raw_data \\\n",
    "    .filter(lambda line: line != large_raw_data_header) \\\n",
    "    .map(lambda line: line.split(\",\")) \\\n",
    "    .map(lambda tokens: (int(tokens[0]), tokens[1], tokens[2])).cache()\n",
    "large_titles = large_data.map(lambda x: (int(x[0]), x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "794bf5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"There are %s movies in the large dataset\" % (large_titles.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12fd22c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large dataset file parsing\n",
    "complete_file = os.path.join(large_dataset_path, 'ratings.csv')\n",
    "complete_raw_data = sc.textFile(complete_file)\n",
    "complete_raw_data_header = complete_raw_data.take(1)[0]\n",
    "complete_data = complete_raw_data \\\n",
    "    .filter(lambda line: line != complete_raw_data_header) \\\n",
    "    .map(lambda line: line.split(\",\")) \\\n",
    "    .map(lambda tokens: (int(tokens[0]), int(tokens[1]), float(tokens[2]))) \\\n",
    "    .cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b763b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('There are %s recommendations in the large dataset' % (complete_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72d2f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts and averages of the ratings\n",
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1])) / nratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "161ef89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the ratings, avg_ratings and counts\n",
    "movie_ID_with_ratings_RDD = (complete_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c22ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New user id\n",
    "new_user_ID = 0\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings = config.user_ratings\n",
    "\n",
    "# parallelize the datasets\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22581fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 225, 4), (0, 322, 3), (0, 492, 4), (0, 104, 5), (0, 335, 3), (0, 640, 2), (0, 773, 3), (0, 348, 3), (0, 723, 2), (0, 354, 1), (0, 346, 4), (0, 923, 2), (0, 425, 3)]\n"
     ]
    }
   ],
   "source": [
    "print('New user ratings: %s' % new_user_ratings_RDD.take(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a8d4297",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_with_new_ratings_RDD = small_data.union(new_user_ratings_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6b3b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time taken to train new model\n",
    "t0 = time.time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfdcd229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model trained in 1.444 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"New model trained in %s seconds\" % round(tt, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e61d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New user recommendation ratings\n",
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings)\n",
    "new_user_unrated_movies_RDD = large_data \\\n",
    "    .filter(lambda x: x[0] not in new_user_ratings_ids) \\\n",
    "    .map(lambda x: (new_user_ID, x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b3c43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(new_user_unrated_movies_RDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54461468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the new ratings\n",
    "recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "#print(recommendations_RDD.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36d68af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "recommendations_rating_RDD = recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "recommendations_rating_title_and_count_RDD = \\\n",
    "    recommendations_rating_RDD.join(large_titles).join(movie_rating_counts_RDD)\n",
    "# print(recommendations_rating_title_and_count_RDD.take(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b97ce621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take and display the recommendations\n",
    "recommendations_rating_title_and_count_RDD = \\\n",
    "    recommendations_rating_title_and_count_RDD \\\n",
    "        .map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "top_movies = recommendations_rating_title_and_count_RDD \\\n",
    "    .filter(lambda r: r[2] >= 15) \\\n",
    "    .takeOrdered(15, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "309ff250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies for you:\n",
      "('\"Man with the Movie Camera', 4.809557770911336, 647)\n",
      "('Louis C.K.: Chewed Up (2008)', 4.658503105031693, 1490)\n",
      "('Minnie and Moskowitz (1971)', 4.647311757349509, 122)\n",
      "(\"Ivan's Childhood (a.k.a. My Name is Ivan) (Ivanovo detstvo) (1962)\", 4.625431675465812, 526)\n",
      "('\"Center of the World', 4.617044178092482, 268)\n",
      "('Louis C.K.: Shameless (2007)', 4.544683777901539, 1868)\n",
      "('\"Affair to Remember', 4.510936566390971, 2370)\n",
      "('Stardust Memories (1980)', 4.505672832614003, 1123)\n",
      "('Louis C.K.: Live at the Beacon Theater (2011)', 4.466593609552823, 1821)\n",
      "('Bachelor Party (1984)', 4.463496079708325, 2099)\n",
      "('\"Summer\\'s Tale', 4.438739224052047, 41)\n",
      "('\"Human Condition III', 4.438739224052047, 91)\n",
      "('Connections (1978)', 4.438739224052047, 49)\n",
      "('\"Woman Under the Influence', 4.438739224052047, 480)\n",
      "('\"Dream of Light (a.k.a. Quince Tree Sun', 4.438739224052047, 18)\n"
     ]
    }
   ],
   "source": [
    "print('Recommended movies for you:\\n%s' %\n",
    "      '\\n'.join(map(str, top_movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d2ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
